{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc03ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adrian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from db.database import Database\n",
    "from db.models import Blueprint\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45bbecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading blueprints: 100%|██████████| 2232/2232 [00:01<00:00, 1521.49it/s]\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "topics = {topic.topic_id: topic for topic in db.get_topics()}\n",
    "posts = {post.post_id: post for post in db.get_posts()}\n",
    "blueprints = {bp.id: bp for bp in db.get_all_blueprints()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fae791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"work\" in stopwords.words('english'))  # Check if \"it\" is in the stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0ffb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    for code_tag in soup.find_all('code', class_='lang-auto'):\n",
    "        code_tag.decompose()\n",
    "    \n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.decompose()\n",
    "    \n",
    "    return soup.get_text().replace('\\n', ' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, ignorable_words=None):\n",
    "    if ignorable_words is None:\n",
    "        ignorable_words = []\n",
    "    ignorable_words = ignorable_words + [\"blueprint\", \"automation\", \"entity\", \"work\"]\n",
    "    text = remove_html(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'’', r\"'\", text)\n",
    "    text = re.sub(r\"[^\\w'\\s]\", '', text)\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub('|'.join(ignorable_words), '', text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d165d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_trans(str: list[str]):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    res = tfidf.fit_transform(str)\n",
    "    return res, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0abc23db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"hi namron 8button switch want use different thing send action example  ing try use 4 different action 4 different thing dim turn turn  se action changed back  processed option lightzigbee_23 wallwitch lightzigbee_24 lamp home can't test look right\",\n",
       " 'https://community.home-assistant.io//t/one-automation-to-manage-all-buttons-on-a-switch/336607')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_corpus_and_url(topic_id):\n",
    "    topic = topics.get(topic_id)\n",
    "    posts = db.get_posts_by_topic_id(topic_id)\n",
    "    tags = topic.tags\n",
    "    if isinstance(tags, str):\n",
    "        try:\n",
    "            tags = ast.literal_eval(tags)\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tags = [lemmatizer.lemmatize(tag) for tag in tags]\n",
    "        except (ValueError, SyntaxError):\n",
    "            tags = [tags]\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tags = [lemmatizer.lemmatize(tag) for tag in tags]\n",
    "    post_contents = [post.cooked for post in posts]\n",
    "    corpus = [preprocessing(text, ignorable_words=tags) for text in post_contents]\n",
    "    corpus = \" \".join(corpus)\n",
    "    return corpus, topic.topic_url\n",
    "\n",
    "corpus, url = get_corpus_and_url(list(topics.keys())[120])\n",
    "corpus, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7977d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8button    action      back       can   changed  different       dim  \\\n",
      "0  0.136083  0.408248  0.136083  0.136083  0.136083   0.408248  0.136083   \n",
      "\n",
      "    example        hi      home  ...        se      send    switch      test  \\\n",
      "0  0.136083  0.136083  0.136083  ...  0.136083  0.136083  0.136083  0.136083   \n",
      "\n",
      "      thing       try      turn       use  wallwitch      want  \n",
      "0  0.272166  0.136083  0.272166  0.272166   0.136083  0.136083  \n",
      "\n",
      "[1 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "res, tfidf = fit_trans([corpus])\n",
    "terms = tfidf.get_feature_names_out()\n",
    "df = pd.DataFrame(res.toarray(), columns=terms)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f630c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: [('zone', 0.5773502691896258), ('leave', 0.5773502691896258), ('duplicate', 0.5773502691896258)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_keywords(tfidf_matrix, feature_names, top_n=5):\n",
    "    \"\"\"\n",
    "    Extract top keywords for each document based on TF-IDF scores.\n",
    "    \n",
    "    Args:\n",
    "        tfidf_matrix: The sparse matrix of TF-IDF scores.\n",
    "        feature_names: List of feature names (terms).\n",
    "        top_n: Number of top keywords to extract per document.\n",
    "    \n",
    "    Returns:\n",
    "        List of lists containing top keywords with score for each document.\n",
    "    \"\"\"\n",
    "    top_keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        # Convert sparse row to dense array\n",
    "        row_array = row.toarray().flatten()\n",
    "        # Get indices of top N scores\n",
    "        top_indices = np.argsort(row_array)[-top_n:][::-1]\n",
    "        # Map indices to feature names\n",
    "        top_terms = [(feature_names[i], row_array[i]) for i in top_indices]\n",
    "        top_keywords.append(top_terms)\n",
    "    return top_keywords\n",
    "\n",
    "# Get top keywords for each document\n",
    "top_keywords_per_doc = get_top_keywords(res, terms, top_n=5)\n",
    "\n",
    "# Print top keywords for the first few documents\n",
    "for i, keywords in enumerate(top_keywords_per_doc[:5]):\n",
    "    print(f\"Document {i+1}: {keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7084066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting languages: 100%|██████████| 2196/2196 [00:35<00:00, 61.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from util.lang_identification import identify_language\n",
    "\n",
    "non_english = {} \n",
    "for bp in tqdm.tqdm(blueprints.values(), desc=\"Detecting languages\"):\n",
    "    lang = identify_language(bp)\n",
    "    if lang != 'en':\n",
    "        non_english[bp] = lang\n",
    "        \n",
    "for bp in non_english:\n",
    "    blueprints.pop(bp.id)\n",
    "blueprints.__len__()\n",
    "\n",
    "groups = db.get_blueprints_per_topic()\n",
    "\n",
    "english_ids = set(blueprints.keys())   \n",
    "filtered_groups = {\n",
    "    topic_id: [bp for bp in bps if bp.id in english_ids]\n",
    "    for topic_id, bps in groups.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "keywords = Counter()\n",
    "for topic_id in list(filtered_groups.keys()):\n",
    "    corpus, _ = get_corpus_and_url(topic_id)\n",
    "    if not corpus.strip():\n",
    "        continue\n",
    "    res, tfidf = fit_trans([corpus])\n",
    "    terms = tfidf.get_feature_names_out()\n",
    "    topic_keywords = get_top_keywords(res, terms, top_n=10)\n",
    "    topic_keywords = [entry[0] for entry in topic_keywords]\n",
    "    keywords.update(topic_keywords)\n",
    "\n",
    "print(keywords.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99220786",
   "metadata": {},
   "source": [
    "### Rake testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78c59e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stage trigger monitor', 9.0),\n",
       " ('state trigger monitors', 8.0),\n",
       " ('sensor’s action attribute', 6.833333333333334),\n",
       " ('action attribute', 4.5),\n",
       " ('sensor’s state', 4.333333333333334),\n",
       " ('short press', 4.0),\n",
       " ('long press', 4.0),\n",
       " ('works great', 4.0),\n",
       " ('z2m binding', 4.0),\n",
       " ('brightness level', 4.0),\n",
       " ('can’t answer', 4.0),\n",
       " ('ikea switch', 4.0),\n",
       " ('variable refers', 4.0),\n",
       " ('hobby programmer', 4.0),\n",
       " ('made product', 4.0),\n",
       " ('on/off switch', 3.666666666666667),\n",
       " ('realy don’t', 3.5),\n",
       " ('on/off function', 3.166666666666667),\n",
       " ('state', 2.0),\n",
       " ('on/off', 1.6666666666666667),\n",
       " ('2 function', 1.5),\n",
       " ('don’t', 1.5),\n",
       " ('based', 1.0),\n",
       " ('it’s', 1.0),\n",
       " ('code', 1.0),\n",
       " ('control', 1.0),\n",
       " ('lights', 1.0),\n",
       " ('dim', 1.0),\n",
       " ('bunch', 1.0),\n",
       " ('bad', 1.0),\n",
       " ('maybee', 1.0),\n",
       " ('rewrite', 1.0),\n",
       " ('dimming', 1.0),\n",
       " ('examples', 1.0),\n",
       " ('question', 1.0),\n",
       " ('zigbee2mqtt', 1.0),\n",
       " ('i’m', 1.0),\n",
       " ('rebuild', 1.0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multi_rake import Rake\n",
    "rake = Rake()\n",
    "full_text = \" \".join(cleaned_texts_topic)\n",
    "keywords = rake.apply(full_text)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345ee26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
