{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adrian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from db.database import Database\n",
    "from db.models import Blueprint\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45bbecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading blueprints: 100%|██████████| 2232/2232 [00:01<00:00, 1442.87it/s]\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "topics = {topic.topic_id: topic for topic in db.get_topics()}\n",
    "posts = {post.post_id: post for post in db.get_posts()}\n",
    "blueprints = {bp.id: bp for bp in db.get_all_blueprints()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fae791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"work\" in stopwords.words('english'))  # Check if \"it\" is in the stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cdcb3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting languages: 100%|██████████| 2232/2232 [00:37<00:00, 59.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1211"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "from util.lang_identification import identify_language\n",
    "\n",
    "non_english = {} \n",
    "for bp in tqdm.tqdm(blueprints.values(), desc=\"Detecting languages\"):\n",
    "    lang = identify_language(bp)\n",
    "    if lang != 'en':\n",
    "        non_english[bp] = lang\n",
    "        \n",
    "for bp in non_english:\n",
    "    blueprints.pop(bp.id)\n",
    "blueprints.__len__()\n",
    "\n",
    "groups = db.get_blueprints_per_topic()\n",
    "\n",
    "english_ids = set(blueprints.keys())   \n",
    "filtered_groups = {\n",
    "    topic_id: [bp for bp in bps if bp.id in english_ids]\n",
    "    for topic_id, bps in groups.items()\n",
    "}\n",
    "filtered_groups.keys().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0ffb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    for code_tag in soup.find_all('code', {'class':['lang-auto','lang-yaml']}):\n",
    "        code_tag.decompose()\n",
    "    \n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.decompose()\n",
    "    \n",
    "    return soup.get_text().replace('\\n', ' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, ignorable_words=None):\n",
    "    if ignorable_words is None:\n",
    "        ignorable_words = []\n",
    "    ignorable_words = ignorable_words + [\"blueprint\", \"automation\", \"entity\", \"work\"]\n",
    "    text = remove_html(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'’', r\"'\", text)\n",
    "    text = re.sub(r\"[^\\w'\\s]\", '', text)\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub('|'.join(ignorable_words), '', text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d4c99",
   "metadata": {},
   "source": [
    "### sklearn TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d165d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_trans(str: list[str]):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    res = tfidf.fit_transform(str)\n",
    "    return res, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0abc23db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"hi namron 8button switch want use different thing send action example  ing try use 4 different action 4 different thing dim turn turn  se action changed back  processed option lightzigbee_23 wallwitch lightzigbee_24 lamp home can't test look right\",\n",
       " 'https://community.home-assistant.io//t/one-automation-to-manage-all-buttons-on-a-switch/336607')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_corpus_and_url(topic_id):\n",
    "    topic = topics.get(topic_id)\n",
    "    posts = db.get_posts_by_topic_id(topic_id)\n",
    "    tags = topic.tags\n",
    "    if isinstance(tags, str):\n",
    "        try:\n",
    "            tags = ast.literal_eval(tags)\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tags = [lemmatizer.lemmatize(tag) for tag in tags]\n",
    "        except (ValueError, SyntaxError):\n",
    "            tags = [tags]\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tags = [lemmatizer.lemmatize(tag) for tag in tags]\n",
    "    post_contents = [post.cooked for post in posts]\n",
    "    corpus = [preprocessing(text, ignorable_words=tags) for text in post_contents]\n",
    "    corpus = \" \".join(corpus)\n",
    "    return corpus, topic.topic_url\n",
    "\n",
    "corpus, url = get_corpus_and_url(list(topics.keys())[120])\n",
    "corpus, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7977d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8button    action      back       can   changed  different       dim  \\\n",
      "0  0.136083  0.408248  0.136083  0.136083  0.136083   0.408248  0.136083   \n",
      "\n",
      "    example        hi      home  ...        se      send    switch      test  \\\n",
      "0  0.136083  0.136083  0.136083  ...  0.136083  0.136083  0.136083  0.136083   \n",
      "\n",
      "      thing       try      turn       use  wallwitch      want  \n",
      "0  0.272166  0.136083  0.272166  0.272166   0.136083  0.136083  \n",
      "\n",
      "[1 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "res, tfidf = fit_trans([corpus])\n",
    "terms = tfidf.get_feature_names_out()\n",
    "df = pd.DataFrame(res.toarray(), columns=terms)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f630c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: [('action', 0.408248290463863), ('different', 0.408248290463863), ('use', 0.2721655269759087)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_keywords(tfidf_matrix, feature_names, top_n=5):\n",
    "    \"\"\"\n",
    "    Extract top keywords for each document based on TF-IDF scores.\n",
    "    \n",
    "    Args:\n",
    "        tfidf_matrix: The sparse matrix of TF-IDF scores.\n",
    "        feature_names: List of feature names (terms).\n",
    "        top_n: Number of top keywords to extract per document.\n",
    "    \n",
    "    Returns:\n",
    "        List of lists containing top keywords with score for each document.\n",
    "    \"\"\"\n",
    "    top_keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        # Convert sparse row to dense array\n",
    "        row_array = row.toarray().flatten()\n",
    "        # Get indices of top N scores\n",
    "        top_indices = np.argsort(row_array)[-top_n:][::-1]\n",
    "        # Map indices to feature names\n",
    "        top_terms = [(feature_names[i], row_array[i]) for i in top_indices]\n",
    "        top_keywords.append(top_terms)\n",
    "    return top_keywords\n",
    "\n",
    "# Get top keywords for each document\n",
    "top_keywords_per_doc = get_top_keywords(res, terms, top_n=3)\n",
    "\n",
    "# Print top keywords for the first few documents\n",
    "for i, keywords in enumerate(top_keywords_per_doc[:3]):\n",
    "    print(f\"Document {i+1}: {keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5a021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting keywords: 100%|██████████| 1211/1211 [10:33<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 374), ('button', 350), ('name', 324), ('action', 322), ('device', 229), ('condition', 223), ('description', 220), ('press', 213), ('light', 201), ('sensor', 182), ('time', 153), ('switch', 148), ('use', 147), ('selector', 144), ('event', 126), ('one', 116), ('remote', 116), ('turn', 111), ('state', 111), ('thanks', 104), ('home', 98), ('trigger', 97), ('set', 91), ('temperature', 88), ('would', 87), ('default', 82), ('brightness', 73), ('sequence', 72), ('control', 70), ('command', 70), ('scene', 69), ('get', 68), ('change', 67), ('like', 66), ('_id', 62), ('using', 61), ('notification', 59), ('value', 58), ('long', 55), ('mode', 55), ('service', 54), ('assistant', 52), ('hi', 49), ('double', 49), ('dimmer', 49), ('motion', 48), ('single', 47), ('ha', 47), ('error', 46), ('ing', 46)] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "keywords = Counter()\n",
    "for topic_id in tqdm.tqdm(list(filtered_groups.keys()), desc=\"Extracting keywords\"):\n",
    "    corpus, _ = get_corpus_and_url(topic_id)\n",
    "    if not corpus.strip():\n",
    "        continue\n",
    "    res, tfidf = fit_trans([corpus])\n",
    "    terms = tfidf.get_feature_names_out()\n",
    "    topic_keywords = get_top_keywords(res, terms, top_n=10)\n",
    "    flat_keywords = [entry[0] for sublist in topic_keywords for entry in sublist]\n",
    "    keywords.update(flat_keywords)\n",
    "\n",
    "print(keywords.most_common(50), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfd4203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input', 374)\n",
      "('button', 350)\n",
      "('name', 324)\n",
      "('action', 322)\n",
      "('device', 229)\n",
      "('condition', 223)\n",
      "('description', 220)\n",
      "('press', 213)\n",
      "('light', 201)\n",
      "('sensor', 182)\n",
      "('time', 153)\n",
      "('switch', 148)\n",
      "('use', 147)\n",
      "('selector', 144)\n",
      "('event', 126)\n",
      "('one', 116)\n",
      "('remote', 116)\n",
      "('turn', 111)\n",
      "('state', 111)\n",
      "('thanks', 104)\n",
      "('home', 98)\n",
      "('trigger', 97)\n",
      "('set', 91)\n",
      "('temperature', 88)\n",
      "('would', 87)\n",
      "('default', 82)\n",
      "('brightness', 73)\n",
      "('sequence', 72)\n",
      "('control', 70)\n",
      "('command', 70)\n",
      "('scene', 69)\n",
      "('get', 68)\n",
      "('change', 67)\n",
      "('like', 66)\n",
      "('_id', 62)\n",
      "('using', 61)\n",
      "('notification', 59)\n",
      "('value', 58)\n",
      "('long', 55)\n",
      "('mode', 55)\n",
      "('service', 54)\n",
      "('assistant', 52)\n",
      "('hi', 49)\n",
      "('double', 49)\n",
      "('dimmer', 49)\n",
      "('motion', 48)\n",
      "('single', 47)\n",
      "('ha', 47)\n",
      "('error', 46)\n",
      "('ing', 46)\n"
     ]
    }
   ],
   "source": [
    "for keyword in keywords.most_common(50):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99220786",
   "metadata": {},
   "source": [
    "### Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78c59e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('zha', 1.0),\n",
       "  ('tweaked', 1.0),\n",
       "  ('blueprint', 1.0),\n",
       "  ('don’t', 1.0),\n",
       "  ('move', 1.0),\n",
       "  ('control', 1.0),\n",
       "  ('switch', 1.0),\n",
       "  ('badge', 1.0),\n",
       "  ('import', 1.0),\n",
       "  ('higher', 1.0)],\n",
       " 'ZHA - IKEA Tradfri on/off remote dual function Inspired by  I tweaked his blueprint for the IKEA Tradfri On/Off switch. Because I don’t use the dimmer function I use the move and move_with_on_off events to control a switch.  Blueprint Code Click the badge to import this Blueprint: (needs Home Assistant Core 2021.3 or higher)',\n",
       " 'https://community.home-assistant.io//t/zha-ikea-tradfri-on-off-remote-dual-function/350877/1')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multi_rake import Rake\n",
    "rake_topic_id = list(filtered_groups.keys())[120]\n",
    "rake_posts = db.get_posts_by_topic_id(rake_topic_id)\n",
    "cleaned_texts_topic = [remove_html(post.cooked) for post in rake_posts]\n",
    "cleaned_texts_topic.insert(0, str(topics.get(rake_topic_id).title))\n",
    "rake = Rake(min_chars=3, max_words=1, language_code='en')\n",
    "rake.stopwords.add('blueprint')\n",
    "full_text = \" \".join(cleaned_texts_topic)\n",
    "keywords = rake.apply(full_text)\n",
    "keywords, full_text, rake_posts[0].post_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345ee26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5ed396",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29dc53cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZHA - IKEA Tradfri', 'ORG'),\n",
       " ('the IKEA Tradfri On/Off', 'ORG'),\n",
       " ('move_with_on_off', 'ORG'),\n",
       " ('Blueprint Code Click', 'WORK_OF_ART'),\n",
       " ('2021.3', 'CARDINAL')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_topic_id = list(filtered_groups.keys())[120]\n",
    "spacy_posts = db.get_posts_by_topic_id(spacy_topic_id)\n",
    "cleaned_texts_spacy = [remove_html(post.cooked) for post in spacy_posts]\n",
    "cleaned_texts_spacy.insert(0, str(topics.get(spacy_topic_id).title))\n",
    "docs = nlp(\" \".join(cleaned_texts_spacy))\n",
    "entities = [(ent.text, ent.label_) for ent in docs.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc933615",
   "metadata": {},
   "source": [
    "### YAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e435044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tradfri', 0.03103101640079281),\n",
       " ('IKEA', 0.03808461270350777),\n",
       " ('ZHA', 0.04764825324554439),\n",
       " ('Inspired', 0.0816591035917088),\n",
       " ('switch', 0.11185385012850924)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yake\n",
    "yake_topic_id = list(filtered_groups.keys())[120]\n",
    "yake_posts = db.get_posts_by_topic_id(yake_topic_id)\n",
    "cleaned_texts_yake = [remove_html(post.cooked) for post in yake_posts]\n",
    "cleaned_texts_yake.insert(0, str(topics.get(yake_topic_id).title))\n",
    "yake_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, top=5)\n",
    "yake_keywords = yake_kw_extractor.extract_keywords(\" \".join(cleaned_texts_yake))\n",
    "yake_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ebfcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_preprocessing(text):\n",
    "    text = remove_html(text)\n",
    "    text = remove_html(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'’', r\"'\", text)\n",
    "    #text = re.sub(r\"[^\\w'\\s]\", '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95d45262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting keywords: 100%|██████████| 100/100 [00:10<00:00,  9.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'press': 8,\n",
       "         'light': 5,\n",
       "         'motion': 3,\n",
       "         'ikea': 3,\n",
       "         'entity': 3,\n",
       "         'scene': 3,\n",
       "         'time': 2,\n",
       "         'simple': 2,\n",
       "         'sensor': 2,\n",
       "         'media': 2,\n",
       "         'ozw': 2,\n",
       "         'turn': 2,\n",
       "         'temperature': 2,\n",
       "         'android': 1,\n",
       "         'fan': 1,\n",
       "         'short': 1,\n",
       "         'set': 1,\n",
       "         'run': 1,\n",
       "         'make': 1,\n",
       "         'telegram': 1,\n",
       "         'volume': 1,\n",
       "         'audio': 1,\n",
       "         'condition': 1,\n",
       "         'double': 1,\n",
       "         'action': 1,\n",
       "         'red': 1,\n",
       "         'device': 1,\n",
       "         'battery': 1,\n",
       "         'enter': 1,\n",
       "         'actionable': 1,\n",
       "         'config': 1,\n",
       "         'window': 1,\n",
       "         'lumi.sensor': 1,\n",
       "         'mute': 1,\n",
       "         'microphone': 1,\n",
       "         'face': 1,\n",
       "         'long': 1,\n",
       "         'generic': 1,\n",
       "         'node': 1,\n",
       "         'master': 1,\n",
       "         'amplifier': 1,\n",
       "         'button': 1,\n",
       "         'gist': 1,\n",
       "         'jung': 1,\n",
       "         'change': 1,\n",
       "         'vacuum': 1,\n",
       "         'works': 1,\n",
       "         'home': 1,\n",
       "         'matrix': 1,\n",
       "         'trigger': 1,\n",
       "         'zooz': 1,\n",
       "         'update': 1,\n",
       "         'heatit': 1,\n",
       "         'twitch': 1,\n",
       "         'list': 1,\n",
       "         'charging': 1,\n",
       "         'dark': 1,\n",
       "         'version': 1,\n",
       "         'aroma': 1,\n",
       "         'alarm': 1,\n",
       "         'ctr.u': 1,\n",
       "         'day': 1,\n",
       "         'dimmer': 1,\n",
       "         'nanomote': 1,\n",
       "         'certificate': 1,\n",
       "         'raise': 1,\n",
       "         'remote': 1,\n",
       "         'rgbgenie': 1,\n",
       "         'hue': 1,\n",
       "         'factory': 1,\n",
       "         'tradfri': 1,\n",
       "         'left': 1,\n",
       "         'hold': 1,\n",
       "         'inovelli': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yake_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, top=1)\n",
    "yake_kw_extractor.stopword_set.add('blueprint')\n",
    "keywords = Counter()\n",
    "for topic_id in tqdm.tqdm(list(filtered_groups.keys())[:100], desc=\"Extracting keywords\"):\n",
    "    posts = db.get_posts_by_topic_id(topic_id)\n",
    "    cleaned_texts = [yake_preprocessing(post.cooked) for post in posts]\n",
    "    cleaned_texts.insert(0, yake_preprocessing(topics.get(topic_id).title))\n",
    "    full_text = \" \".join(cleaned_texts)\n",
    "    tags = topics.get(topic_id).tags\n",
    "    if isinstance(tags, str):\n",
    "        try:\n",
    "            tags = ast.literal_eval(tags)\n",
    "        except (ValueError, SyntaxError):\n",
    "            tags = [tags]\n",
    "    #print(f\"Topic ID: {topic_id}, Tags: {tags}\")\n",
    "    for tag in tags:\n",
    "        yake_kw_extractor.stopword_set.add(tag.lower())\n",
    "    yake_keywords = yake_kw_extractor.extract_keywords(full_text)\n",
    "    yake_keywords = [kw for kw, score in yake_keywords]\n",
    "    keywords.update(yake_keywords)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83196757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
