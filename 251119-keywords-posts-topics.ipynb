{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc03ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adrian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from db.database import Database\n",
    "from db.models import Blueprint\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45bbecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading blueprints: 100%|██████████| 2232/2232 [00:01<00:00, 1212.98it/s]\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "topics = {topic.topic_id: topic for topic in db.get_topics()}\n",
    "posts = {post.post_id: post for post in db.get_posts()}\n",
    "blueprints = {bp.id: bp for bp in db.get_all_blueprints()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fae791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"work\" in stopwords.words('english'))  # Check if \"it\" is in the stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cdcb3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adrian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Detecting languages: 100%|██████████| 2232/2232 [00:38<00:00, 58.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1211"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm\n",
    "from util.lang_identification import identify_language_yaml\n",
    "\n",
    "non_english = {} \n",
    "for bp in tqdm.tqdm(blueprints.values(), desc=\"Detecting languages\"):\n",
    "    lang = identify_language_yaml(bp.blueprint_code)\n",
    "    if lang != 'en':\n",
    "        non_english[bp] = lang\n",
    "        \n",
    "for bp in non_english:\n",
    "    blueprints.pop(bp.id)\n",
    "blueprints.__len__()\n",
    "\n",
    "groups = db.get_blueprints_per_topic()\n",
    "\n",
    "english_ids = set(blueprints.keys())   \n",
    "filtered_groups = {\n",
    "    topic_id: [bp for bp in bps if bp.id in english_ids]\n",
    "    for topic_id, bps in groups.items()\n",
    "}\n",
    "filtered_groups.keys().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0ffb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    for code_tag in soup.find_all(\"code\", {\"class\":[\"lang-auto\",\"lang-yaml\"]}):\n",
    "        code_tag.decompose()\n",
    "    \n",
    "    for a_tag in soup.find_all(\"a\"):\n",
    "        a_tag.decompose()\n",
    "    \n",
    "    return soup.get_text().replace(\"\\n\", \" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018f9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, ignorable_words=None):\n",
    "    if ignorable_words is None:\n",
    "        ignorable_words = []\n",
    "    ignorable_words = ignorable_words + [\"blueprint\", \"automation\", \"entity\", \"work\"]\n",
    "    text = remove_html(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"’\", r\"'\", text)\n",
    "    text = re.sub(r\"[^\\w'\\s]\", \"\", text)\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stopwords.words(\"english\")]\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(\"|\".join(ignorable_words), \"\", text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d4c99",
   "metadata": {},
   "source": [
    "### sklearn TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d165d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_trans(str: list[str]):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    res = tfidf.fit_transform(str)\n",
    "    return res, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0abc23db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"hi namron 8button switch want use different thing send action example  ing try use 4 different action 4 different thing dim turn turn  se action changed back  processed option lightzigbee_23 wallwitch lightzigbee_24 lamp home can't test look right\",\n",
       " 'https://community.home-assistant.io//t/one-automation-to-manage-all-buttons-on-a-switch/336607')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_corpus_and_url(topic_id):\n",
    "    topic = topics.get(topic_id)\n",
    "    posts = db.get_posts_by_topic_id(topic_id)\n",
    "    tags = topic.tags\n",
    "    if isinstance(tags, str):\n",
    "        try:\n",
    "            tags = ast.literal_eval(tags)\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tags = [lemmatizer.lemmatize(tag) for tag in tags]\n",
    "        except (ValueError, SyntaxError):\n",
    "            tags = [tags]\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tags = [lemmatizer.lemmatize(tag) for tag in tags]\n",
    "    post_contents = [post.cooked for post in posts]\n",
    "    corpus = [preprocessing(text, ignorable_words=tags) for text in post_contents]\n",
    "    corpus = \" \".join(corpus)\n",
    "    return corpus, topic.topic_url\n",
    "\n",
    "corpus, url = get_corpus_and_url(list(topics.keys())[120])\n",
    "corpus, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7977d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8button    action      back       can   changed  different       dim  \\\n",
      "0  0.136083  0.408248  0.136083  0.136083  0.136083   0.408248  0.136083   \n",
      "\n",
      "    example        hi      home  ...        se      send    switch      test  \\\n",
      "0  0.136083  0.136083  0.136083  ...  0.136083  0.136083  0.136083  0.136083   \n",
      "\n",
      "      thing       try      turn       use  wallwitch      want  \n",
      "0  0.272166  0.136083  0.272166  0.272166   0.136083  0.136083  \n",
      "\n",
      "[1 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "res, tfidf = fit_trans([corpus])\n",
    "terms = tfidf.get_feature_names_out()\n",
    "df = pd.DataFrame(res.toarray(), columns=terms)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: [('action', 0.408248290463863), ('different', 0.408248290463863), ('use', 0.2721655269759087)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_keywords(tfidf_matrix, feature_names, top_n=5):\n",
    "    top_keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        # Convert sparse row to dense array\n",
    "        row_array = row.toarray().flatten()\n",
    "        # Get indices of top N scores\n",
    "        top_indices = np.argsort(row_array)[-top_n:][::-1]\n",
    "        # Map indices to feature names\n",
    "        top_terms = [(feature_names[i], row_array[i]) for i in top_indices]\n",
    "        top_keywords.append(top_terms)\n",
    "    return top_keywords\n",
    "\n",
    "# Get top keywords for each document\n",
    "top_keywords_per_doc = get_top_keywords(res, terms, top_n=3)\n",
    "\n",
    "# Print top keywords for the first few documents\n",
    "for i, keywords in enumerate(top_keywords_per_doc[:3]):\n",
    "    print(f\"Document {i+1}: {keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5a021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting keywords: 100%|██████████| 1211/1211 [10:33<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 374), ('button', 350), ('name', 324), ('action', 322), ('device', 229), ('condition', 223), ('description', 220), ('press', 213), ('light', 201), ('sensor', 182), ('time', 153), ('switch', 148), ('use', 147), ('selector', 144), ('event', 126), ('one', 116), ('remote', 116), ('turn', 111), ('state', 111), ('thanks', 104), ('home', 98), ('trigger', 97), ('set', 91), ('temperature', 88), ('would', 87), ('default', 82), ('brightness', 73), ('sequence', 72), ('control', 70), ('command', 70), ('scene', 69), ('get', 68), ('change', 67), ('like', 66), ('_id', 62), ('using', 61), ('notification', 59), ('value', 58), ('long', 55), ('mode', 55), ('service', 54), ('assistant', 52), ('hi', 49), ('double', 49), ('dimmer', 49), ('motion', 48), ('single', 47), ('ha', 47), ('error', 46), ('ing', 46)] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "keywords = Counter()\n",
    "for topic_id in tqdm.tqdm(list(filtered_groups.keys()), desc=\"Extracting keywords\"):\n",
    "    corpus, _ = get_corpus_and_url(topic_id)\n",
    "    if not corpus.strip():\n",
    "        continue\n",
    "    res, tfidf = fit_trans([corpus])\n",
    "    terms = tfidf.get_feature_names_out()\n",
    "    topic_keywords = get_top_keywords(res, terms, top_n=10)\n",
    "    flat_keywords = [entry[0] for sublist in topic_keywords for entry in sublist]\n",
    "    keywords.update(flat_keywords)\n",
    "\n",
    "print(keywords.most_common(50), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfd4203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input', 374)\n",
      "('button', 350)\n",
      "('name', 324)\n",
      "('action', 322)\n",
      "('device', 229)\n",
      "('condition', 223)\n",
      "('description', 220)\n",
      "('press', 213)\n",
      "('light', 201)\n",
      "('sensor', 182)\n",
      "('time', 153)\n",
      "('switch', 148)\n",
      "('use', 147)\n",
      "('selector', 144)\n",
      "('event', 126)\n",
      "('one', 116)\n",
      "('remote', 116)\n",
      "('turn', 111)\n",
      "('state', 111)\n",
      "('thanks', 104)\n",
      "('home', 98)\n",
      "('trigger', 97)\n",
      "('set', 91)\n",
      "('temperature', 88)\n",
      "('would', 87)\n",
      "('default', 82)\n",
      "('brightness', 73)\n",
      "('sequence', 72)\n",
      "('control', 70)\n",
      "('command', 70)\n",
      "('scene', 69)\n",
      "('get', 68)\n",
      "('change', 67)\n",
      "('like', 66)\n",
      "('_id', 62)\n",
      "('using', 61)\n",
      "('notification', 59)\n",
      "('value', 58)\n",
      "('long', 55)\n",
      "('mode', 55)\n",
      "('service', 54)\n",
      "('assistant', 52)\n",
      "('hi', 49)\n",
      "('double', 49)\n",
      "('dimmer', 49)\n",
      "('motion', 48)\n",
      "('single', 47)\n",
      "('ha', 47)\n",
      "('error', 46)\n",
      "('ing', 46)\n"
     ]
    }
   ],
   "source": [
    "for keyword in keywords.most_common(50):\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99220786",
   "metadata": {},
   "source": [
    "### Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c59e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('deconz', 1.0),\n",
       "  ('this', 1.0),\n",
       "  ('ups', 1.0),\n",
       "  ('cool', 1.0),\n",
       "  ('single', 1.0),\n",
       "  ('thanks', 1.0),\n",
       "  ('device_id', 1.0),\n",
       "  ('hey', 1.0),\n",
       "  ('error', 1.0),\n",
       "  ('undefinederror', 1.0),\n",
       "  ('hassio/supervised', 1.0),\n",
       "  ('100%', 1.0),\n",
       "  ('hmm', 1.0),\n",
       "  ('events', 1.0),\n",
       "  ('deconz_event', 1.0),\n",
       "  ('anyways', 1.0),\n",
       "  ('but', 1.0)],\n",
       " 'deCONZ - Ikea Tradfri Shortcut Button based on this  Blueprint. Nice I haven’t got a shortcut button myself to test for you. But the code looks good Thanks! I really like them. I got two of them and they work good so far. Deconz already supports them but they do not show up in the phoscon app. In HA you can not directly control them via Devices, but the events work. So the Blueprint makes even more sense here! How do I have to add the shortcut button in order to use that blueprint? First adding the button to deconz? Search for new devices in the Phoscon app (it wont show up there as the app is not updated yet). Just look into your devices in the Deconz Integration in Home Assistant. Once your device is listed you can use it via the blueprint. Its a little confusing right now but the button works fine. Thanks for the blueprint. What’s the difference between yours and the one it is based on? I am facing the same problem. Please give some solution to us. this blueprint is for the new ikea Tradfri  while the one it’s based on is the ikea Tradfri . they both work very similar except that the shortcut button only has one button while the on/off button has two. Ups. Sorry I didn’t notice the title. Cool. I’ll try it. Can you add my homeassistant button? i might do this when I get some time on my hands, iam pretty busy atm. you can add the blueprint this way: copy url of this thread  -> go to blueprints in the ui -> add template -> paste the link Thanks. Yes I already added it that way and it works perfectly. In the current deconz version the button is detected and reported to HA but it is not visible in phoscon interface. Suddenly Deconz started sending double events for the shortcut button. Does anyone have the same problem? i haven’t experienced them yet. a quick fix would be to set mode to “single” and put a 1s delay after the choose condition. That works perfectly. Thanks. please help me. i have error message in blueprint: unknown tag !<!input> at line 33, column 31: device_id: !input ‘remote’ Hi! Thanks for your work! I add shortcut button from phoscon beta, but in home assistnt i see only device (without entiies). I add your bluepint but not works. Log say “trigger missing” Hey , Potentially dumb question, can the shortcut buttons support double and triple clicks at this early stage? Cheers Linton Today I’ve added a shortcut button in HA via deCONZ. Next step was using this blueprint. Unfortunately I’m not able to have this work properly. I receive this error: Error: UndefinedError: ‘dict object’ has no attribute ‘event’ The only thing I did, was creating blueprint, add the button, add the device, and that should be it. Also a normal automation doesn’t work. This is my config:  What am I doing wrong here  ? Thanks for your help I’m on the latest version of Home Assistant (hassio/supervised), using the latest version of the deCONZ addon, and a Conbee II updated with the latest firmware - l’ve added/synced my (one and only) Ikea Tradfri Shortcut button in Phoscon (successfully from what I can tell). Home Assistant lists it as well, I can see the battery level (100%) but it does not work in automations, not by event nor via blueprint - what can I do/check to try and resolve this? Hmm, dunno why but after debugging events in Home Assistant (dev tools, events, listen to ”deconz_event”) and not seeing any events for this particular button/switch I removed and te-synced it a couple of times… finally it works as intended. But many times it just registered in Phoscon, showed up in deconz/visible by vnc, but no events… not working when added as a switch to a group in Phoscon either… Anyways, perhaps helps someone else to know Hi  Is it possible to set a delay fort short press. From time to time it fires dubbel events, switch on and the switch off in a second. Could se that someone did for the blueprint in zha. Maybe 300ms delay.  /Peter I’ve faced the same situation where adding the Shortcut button was successful, available in Phoscon and HA, but no triggered events would be detected through the Dev tools. By leaving it still for two hours in this state, it solved by itself and was then able to see triggered events! No need to re-sync it several times, being patient seems to be the key. I was plenty patient (; it didnt heal on its own )); But, its been working like a champ ever since I got it up and running',\n",
       " 'https://community.home-assistant.io//t/deconz-ikea-tradfri-shortcut-button/282684/1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multi_rake import Rake\n",
    "rake_topic_id = list(filtered_groups.keys())[115]\n",
    "rake_posts = db.get_posts_by_topic_id(rake_topic_id)\n",
    "cleaned_texts_topic = [remove_html(post.cooked) for post in rake_posts]\n",
    "cleaned_texts_topic.insert(0, str(topics.get(rake_topic_id).title))\n",
    "rake = Rake(min_chars=3, max_words=1)\n",
    "rake.stopwords.add('blueprint')\n",
    "full_text = \" \".join(cleaned_texts_topic)\n",
    "keywords = rake.apply(full_text)\n",
    "keywords, full_text, rake_posts[0].post_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345ee26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5ed396",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29dc53cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ZHA - IKEA Tradfri on/off remote dual function Inspired by  I tweaked his blueprint for the IKEA Tradfri On/Off switch. Because I don’t use the dimmer function I use the move and move_with_on_off events to control a switch.  Blueprint Code Click the badge to import this Blueprint: (needs Home Assistant Core 2021.3 or higher),\n",
       " Counter({'NOUN': 12,\n",
       "          'PROPN': 11,\n",
       "          'VERB': 8,\n",
       "          'PUNCT': 6,\n",
       "          'DET': 6,\n",
       "          'ADP': 4,\n",
       "          'PRON': 4,\n",
       "          'ADJ': 3,\n",
       "          'PART': 3,\n",
       "          'SYM': 2,\n",
       "          'SPACE': 2,\n",
       "          'CCONJ': 2,\n",
       "          'SCONJ': 1,\n",
       "          'AUX': 1,\n",
       "          'NUM': 1}),\n",
       " '[\"zha\", \"blueprint\"]')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "#nlp.add_pipe(\"keyword_extractor\", last=True, config={\"top_n\": 10, \"min_ngram\": 3, \"max_ngram\": 3, \"strict\": True, \"top_n_sent\": 3})\n",
    "spacy_topic_id = list(filtered_groups.keys())[120]\n",
    "spacy_posts = db.get_posts_by_topic_id(spacy_topic_id)\n",
    "cleaned_texts_spacy = [remove_html(post.cooked) for post in spacy_posts]\n",
    "cleaned_texts_spacy.insert(0, str(topics.get(spacy_topic_id).title))\n",
    "docs = nlp(\" \".join(cleaned_texts_spacy))\n",
    "entities = Counter([token.pos_ for token in docs])\n",
    "docs, entities, topics.get(spacy_topic_id).tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9279efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('assistant', 1)\n",
      "('core', 1)\n",
      "('dual', 1)\n",
      "('higher', 1)\n",
      "('dimmer', 1)\n",
      "('function', 1)\n",
      "('zha', 1)\n",
      "('badge', 1)\n",
      "('ikea', 1)\n",
      "('switch', 1)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "    return result\n",
    "text = \" \".join(cleaned_texts_spacy)\n",
    "output = set(get_hotwords(text))\n",
    "most_common_list = Counter(output).most_common(10)\n",
    "for item in most_common_list:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc933615",
   "metadata": {},
   "source": [
    "### YAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17112762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_preprocessing(text):\n",
    "    text = remove_html(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'’', r\"'\", text)\n",
    "    text = re.sub(r\"[^\\w'\\s]\", '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e435044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('button', 0.008983209970610917),\n",
       "  ('remote', 0.01101808167018563),\n",
       "  ('mode', 0.012965884183608533),\n",
       "  ('light', 0.0135164559500364),\n",
       "  ('press', 0.016636531121412636)],\n",
       " [],\n",
       " 'https://community.home-assistant.io//t/zha-linkind-5-key-remote-control-button-zbt-rgbw-switch-d0801-using-switch-modes/358781/1')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yake\n",
    "yake_topic_id = list(filtered_groups.keys())[250]\n",
    "yake_posts = db.get_posts_by_topic_id(yake_topic_id)\n",
    "cleaned_texts_yake = [yake_preprocessing(post.cooked) for post in yake_posts]\n",
    "cleaned_texts_yake.insert(0, yake_preprocessing(str(topics.get(yake_topic_id).title)))\n",
    "yake_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, top=5)\n",
    "yake_kw_extractor.stopword_set.add('blueprint')\n",
    "tags = topics.get(topic_id).tags\n",
    "if isinstance(tags, str):\n",
    "    try:\n",
    "        tags = ast.literal_eval(tags)\n",
    "    except (ValueError, SyntaxError):\n",
    "        tags = [tags]\n",
    "for tag in tags:\n",
    "    yake_kw_extractor.stopword_set.add(tag.lower())\n",
    "yake_keywords = yake_kw_extractor.extract_keywords(\" \".join(cleaned_texts_yake))\n",
    "yake_keywords, tags, yake_posts[0].post_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d45262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting keywords: 100%|██████████| 1211/1211 [03:22<00:00,  5.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'press': 117,\n",
       "         'light': 105,\n",
       "         'work': 81,\n",
       "         'remote': 74,\n",
       "         'device': 70,\n",
       "         'temperature': 56,\n",
       "         'action': 56,\n",
       "         'home': 55,\n",
       "         'turn': 55,\n",
       "         'scene': 47,\n",
       "         'motion': 45,\n",
       "         'sensor': 38,\n",
       "         'entity': 38,\n",
       "         'event': 37,\n",
       "         'hue': 37,\n",
       "         'ikea': 33,\n",
       "         'state': 33,\n",
       "         'dimmer': 32,\n",
       "         'input': 32,\n",
       "         'brightness': 32,\n",
       "         'set': 29,\n",
       "         'actions': 29,\n",
       "         'lights': 29,\n",
       "         'long': 28,\n",
       "         'door': 27,\n",
       "         'control': 26,\n",
       "         'events': 25,\n",
       "         'color': 25,\n",
       "         'switches': 24,\n",
       "         'trigger': 24,\n",
       "         'works': 24,\n",
       "         'media': 22,\n",
       "         'assistant': 22,\n",
       "         'version': 20,\n",
       "         'mode': 19,\n",
       "         'working': 19,\n",
       "         'single': 17,\n",
       "         'tradfri': 17,\n",
       "         'devices': 17,\n",
       "         'volume': 16,\n",
       "         'window': 16,\n",
       "         'hold': 16,\n",
       "         'wireless': 16,\n",
       "         'controller': 16,\n",
       "         'double': 15,\n",
       "         'battery': 15,\n",
       "         'pico': 15,\n",
       "         'entities': 15,\n",
       "         'smart': 14,\n",
       "         'power': 14,\n",
       "         'link': 14,\n",
       "         'shelly': 13,\n",
       "         'select': 13,\n",
       "         'timer': 13,\n",
       "         'onoff': 12,\n",
       "         'fan': 12,\n",
       "         'tap': 12,\n",
       "         'dial': 12,\n",
       "         'add': 11,\n",
       "         'based': 11,\n",
       "         'binary': 11,\n",
       "         'target': 11,\n",
       "         'google': 11,\n",
       "         'dimming': 11,\n",
       "         'list': 10,\n",
       "         'import': 10,\n",
       "         'change': 10,\n",
       "         'boolean': 10,\n",
       "         'integration': 10,\n",
       "         'humidity': 10,\n",
       "         'code': 10,\n",
       "         'heating': 10,\n",
       "         'cube': 10,\n",
       "         'day': 10,\n",
       "         'app': 10,\n",
       "         'camera': 10,\n",
       "         'inovelli': 9,\n",
       "         'time': 9,\n",
       "         'player': 9,\n",
       "         'person': 9,\n",
       "         'zooz': 9,\n",
       "         'charging': 9,\n",
       "         'click': 9,\n",
       "         'helper': 9,\n",
       "         'group': 9,\n",
       "         'room': 9,\n",
       "         'triggers': 9,\n",
       "         'condition': 8,\n",
       "         'opple': 8,\n",
       "         'support': 8,\n",
       "         'default': 8,\n",
       "         'alarm': 8,\n",
       "         'update': 8,\n",
       "         'error': 8,\n",
       "         'fibaro': 8,\n",
       "         'styrbar': 8,\n",
       "         'wall': 8,\n",
       "         'price': 8,\n",
       "         'keypad': 8,\n",
       "         'user': 7,\n",
       "         'short': 7,\n",
       "         'button': 7,\n",
       "         'sensors': 7,\n",
       "         'unavailable': 7,\n",
       "         'philips': 7,\n",
       "         'sun': 7,\n",
       "         'model': 7,\n",
       "         'simple': 6,\n",
       "         'thermostat': 6,\n",
       "         'selector': 6,\n",
       "         'left': 6,\n",
       "         'lighting': 6,\n",
       "         'bulbs': 6,\n",
       "         'zwavejs': 6,\n",
       "         'knob': 6,\n",
       "         'trv': 6,\n",
       "         'multiple': 6,\n",
       "         'open': 6,\n",
       "         'moes': 6,\n",
       "         'file': 6,\n",
       "         'water': 6,\n",
       "         'doorbell': 6,\n",
       "         'command': 6,\n",
       "         'image': 6,\n",
       "         'create': 5,\n",
       "         'minutes': 5,\n",
       "         'run': 5,\n",
       "         'threshold': 5,\n",
       "         'telegram': 5,\n",
       "         'red': 5,\n",
       "         'node': 5,\n",
       "         'level': 5,\n",
       "         'zone': 5,\n",
       "         'config': 5,\n",
       "         'template': 5,\n",
       "         'alert': 5,\n",
       "         'temp': 5,\n",
       "         'smoke': 5,\n",
       "         'sonos': 5,\n",
       "         'side': 5,\n",
       "         'speed': 5,\n",
       "         'post': 5,\n",
       "         'led': 5,\n",
       "         'awtrix': 5,\n",
       "         'display': 5,\n",
       "         'send': 5,\n",
       "         'reminder': 5,\n",
       "         'phone': 5,\n",
       "         'message': 5,\n",
       "         'snapshot': 5,\n",
       "         'blind': 4,\n",
       "         'custom': 4,\n",
       "         'night': 4,\n",
       "         'url': 4,\n",
       "         'relay': 4,\n",
       "         'release': 4,\n",
       "         'keyfob': 4,\n",
       "         'frigate': 4,\n",
       "         'push': 4,\n",
       "         'shortcut': 4,\n",
       "         'topic': 4,\n",
       "         'rocker': 4,\n",
       "         'mijia': 4,\n",
       "         'smartthings': 4,\n",
       "         'bathroom': 4,\n",
       "         'tracker': 4,\n",
       "         'gateway': 4,\n",
       "         'updated': 4,\n",
       "         'case': 4,\n",
       "         'status': 4,\n",
       "         'air': 4,\n",
       "         'scenes': 4,\n",
       "         'tibber': 4,\n",
       "         'date': 4,\n",
       "         'namron': 4,\n",
       "         'active': 4,\n",
       "         'bulb': 4,\n",
       "         'description': 4,\n",
       "         'hvac': 4,\n",
       "         'key': 4,\n",
       "         'vesternet': 4,\n",
       "         'position': 4,\n",
       "         'pump': 4,\n",
       "         'weather': 4,\n",
       "         'text': 4,\n",
       "         'calendar': 4,\n",
       "         'plant': 4,\n",
       "         'somrig': 4,\n",
       "         'external': 4,\n",
       "         'alarmo': 4,\n",
       "         'make': 3,\n",
       "         'notify': 3,\n",
       "         'ozw': 3,\n",
       "         'reset': 3,\n",
       "         'actionable': 3,\n",
       "         'folder': 3,\n",
       "         'lumisensor': 3,\n",
       "         'activity': 3,\n",
       "         'face': 3,\n",
       "         'people': 3,\n",
       "         'music': 3,\n",
       "         'configurable': 3,\n",
       "         'current': 3,\n",
       "         'truncated': 3,\n",
       "         'speaker': 3,\n",
       "         'sunset': 3,\n",
       "         'nanomote': 3,\n",
       "         'aeotec': 3,\n",
       "         'delay': 3,\n",
       "         'yaml': 3,\n",
       "         'cycle': 3,\n",
       "         'added': 3,\n",
       "         'webhook': 3,\n",
       "         'toggle': 3,\n",
       "         'windows': 3,\n",
       "         'issue': 3,\n",
       "         'garage': 3,\n",
       "         'turned': 3,\n",
       "         'defined': 3,\n",
       "         'transition': 3,\n",
       "         'supported': 3,\n",
       "         'sync': 3,\n",
       "         'synchronize': 3,\n",
       "         'great': 3,\n",
       "         'wind': 3,\n",
       "         'dim': 3,\n",
       "         'xbox': 3,\n",
       "         'legacy': 3,\n",
       "         'colors': 3,\n",
       "         'openclose': 3,\n",
       "         'lock': 3,\n",
       "         'counter': 3,\n",
       "         'elevation': 3,\n",
       "         'paddle': 3,\n",
       "         'duration': 3,\n",
       "         'loratap': 3,\n",
       "         'danfoss': 3,\n",
       "         'number': 3,\n",
       "         'symfonisk': 3,\n",
       "         'running': 3,\n",
       "         'movie': 3,\n",
       "         'shared': 3,\n",
       "         'mini': 3,\n",
       "         'blinds': 3,\n",
       "         'occupancy': 3,\n",
       "         'created': 3,\n",
       "         'hours': 3,\n",
       "         'rotation': 3,\n",
       "         'dimmers': 3,\n",
       "         'presses': 3,\n",
       "         'colour': 3,\n",
       "         'codes': 3,\n",
       "         'high': 3,\n",
       "         'agent': 3,\n",
       "         'triple': 3,\n",
       "         'printer': 3,\n",
       "         'plants': 3,\n",
       "         'automatically': 3,\n",
       "         'offset': 3,\n",
       "         'pool': 3,\n",
       "         'machine': 3,\n",
       "         'wallmote': 3,\n",
       "         'find': 3,\n",
       "         'task': 3,\n",
       "         'calibration': 3,\n",
       "         'tado': 3,\n",
       "         'aurora': 3,\n",
       "         'presence': 3,\n",
       "         'empty': 3,\n",
       "         'gang': 3,\n",
       "         'rodret': 3,\n",
       "         'detector': 3,\n",
       "         'reminders': 3,\n",
       "         'tts': 2,\n",
       "         'audio': 2,\n",
       "         'leave': 2,\n",
       "         'opened': 2,\n",
       "         'mute': 2,\n",
       "         'playing': 2,\n",
       "         'matrix': 2,\n",
       "         'system': 2,\n",
       "         'controlled': 2,\n",
       "         'quad': 2,\n",
       "         'certificate': 2,\n",
       "         'lower': 2,\n",
       "         'longer': 2,\n",
       "         'cluster': 2,\n",
       "         'data': 2,\n",
       "         'round': 2,\n",
       "         'view': 2,\n",
       "         'adaptive': 2,\n",
       "         'network': 2,\n",
       "         'forum': 2,\n",
       "         'playlist': 2,\n",
       "         'play': 2,\n",
       "         'sengled': 2,\n",
       "         'zones': 2,\n",
       "         'schedule': 2,\n",
       "         'priority': 2,\n",
       "         'homeseer': 2,\n",
       "         'tablet': 2,\n",
       "         'switched': 2,\n",
       "         'harmony': 2,\n",
       "         'valid': 2,\n",
       "         'restore': 2,\n",
       "         'lightturn': 2,\n",
       "         'purifier': 2,\n",
       "         'download': 2,\n",
       "         'users': 2,\n",
       "         'conditions': 2,\n",
       "         'clear': 2,\n",
       "         'helpers': 2,\n",
       "         'sleep': 2,\n",
       "         'installation': 2,\n",
       "         'snooze': 2,\n",
       "         'homematic': 2,\n",
       "         'ecodim': 2,\n",
       "         'channel': 2,\n",
       "         'virtual': 2,\n",
       "         'lidl': 2,\n",
       "         'fast': 2,\n",
       "         'wallcs': 2,\n",
       "         'bands': 2,\n",
       "         'vacuum': 2,\n",
       "         'rest': 2,\n",
       "         'commands': 2,\n",
       "         'car': 2,\n",
       "         'ihc': 2,\n",
       "         'amber': 2,\n",
       "         'nodon': 2,\n",
       "         'persistent': 2,\n",
       "         'ccu': 2,\n",
       "         'line': 2,\n",
       "         'garbage': 2,\n",
       "         'zigfred': 2,\n",
       "         'uno': 2,\n",
       "         'fixed': 2,\n",
       "         'matter': 2,\n",
       "         'leak': 2,\n",
       "         'maximum': 2,\n",
       "         'tautulli': 2,\n",
       "         'blu': 2,\n",
       "         'gejasco': 2,\n",
       "         'referred': 2,\n",
       "         'setup': 2,\n",
       "         'caller': 2,\n",
       "         'valve': 2,\n",
       "         'mobile': 2,\n",
       "         'blue': 2,\n",
       "         'full': 2,\n",
       "         'conversation': 2,\n",
       "         'manual': 2,\n",
       "         'repository': 2,\n",
       "         'initial': 2,\n",
       "         'made': 2,\n",
       "         'manufacturer': 2,\n",
       "         'coffee': 2,\n",
       "         'collection': 2,\n",
       "         'put': 2,\n",
       "         'quirk': 2,\n",
       "         'core': 2,\n",
       "         'icon': 2,\n",
       "         'leds': 2,\n",
       "         'usage': 2,\n",
       "         'todo': 2,\n",
       "         'watch': 2,\n",
       "         'bypass': 2,\n",
       "         'experimental': 2,\n",
       "         'schneider': 2,\n",
       "         'item': 2,\n",
       "         'optional': 2,\n",
       "         'service': 2,\n",
       "         'top': 2,\n",
       "         'sunricher': 2,\n",
       "         'exclude': 2,\n",
       "         'happy': 2,\n",
       "         'detectors': 2,\n",
       "         'json': 2,\n",
       "         'offline': 2,\n",
       "         'wled': 2,\n",
       "         'inputs': 2,\n",
       "         'cost': 2,\n",
       "         'pause': 2,\n",
       "         'station': 2,\n",
       "         'android': 1,\n",
       "         'notification': 1,\n",
       "         'fandimmer': 1,\n",
       "         'allowance': 1,\n",
       "         'nice': 1,\n",
       "         'additional': 1,\n",
       "         'test': 1,\n",
       "         'return': 1,\n",
       "         'perform': 1,\n",
       "         'assigned': 1,\n",
       "         'clip': 1,\n",
       "         'attribute': 1,\n",
       "         'enter': 1,\n",
       "         'sensorteams': 1,\n",
       "         'microphone': 1,\n",
       "         'macos': 1,\n",
       "         'remotec': 1,\n",
       "         'alexa': 1,\n",
       "         'amplifier': 1,\n",
       "         'friends': 1,\n",
       "         'buttons': 1,\n",
       "         'jung': 1,\n",
       "         'yeelight': 1,\n",
       "         'days': 1,\n",
       "         'week': 1,\n",
       "         'lamp': 1,\n",
       "         'note': 1,\n",
       "         'zdim': 1,\n",
       "         'multiclick': 1,\n",
       "         'twitch': 1,\n",
       "         'stream': 1,\n",
       "         'devolo': 1,\n",
       "         'theme': 1,\n",
       "         'dark': 1,\n",
       "         'aroma': 1,\n",
       "         'diffusers': 1,\n",
       "         'discovery': 1,\n",
       "         'trådfri': 1,\n",
       "         'ctru': 1,\n",
       "         'airam': 1,\n",
       "         'ssl': 1,\n",
       "         'raise': 1,\n",
       "         'thread': 1,\n",
       "         'rgbgenie': 1,\n",
       "         'osram': 1,\n",
       "         'presshold': 1,\n",
       "         'happen': 1,\n",
       "         'endpoint': 1,\n",
       "         'callbacks': 1,\n",
       "         'handle': 1,\n",
       "         'identifiers': 1,\n",
       "         'phoscon': 1,\n",
       "         'object': 1,\n",
       "         'ding': 1,\n",
       "         'dong': 1,\n",
       "         'end': 1,\n",
       "         'choose': 1,\n",
       "         'feed': 1,\n",
       "         'flag': 1,\n",
       "         'swipe': 1,\n",
       "         'nuki': 1,\n",
       "         'bridge': 1,\n",
       "         'sequence': 1,\n",
       "         'turning': 1,\n",
       "         'icy': 1,\n",
       "         'install': 1,\n",
       "         'secondary': 1,\n",
       "         'primary': 1,\n",
       "         'grill': 1,\n",
       "         'backup': 1,\n",
       "         'monthly': 1,\n",
       "         'pyscript': 1,\n",
       "         'logic': 1,\n",
       "         'chromecast': 1,\n",
       "         'higher': 1,\n",
       "         'xmpp': 1,\n",
       "         'gestures': 1,\n",
       "         'nanoleaf': 1,\n",
       "         'tag': 1,\n",
       "         'zwp': 1,\n",
       "         'miflora': 1,\n",
       "         'immediately': 1,\n",
       "         'october': 1,\n",
       "         'triggering': 1,\n",
       "         'coordinate': 1,\n",
       "         'zemismart': 1,\n",
       "         'automated': 1,\n",
       "         'show': 1,\n",
       "         'screen': 1,\n",
       "         'irrigation': 1,\n",
       "         'shower': 1,\n",
       "         'hygrostat': 1,\n",
       "         'lumi': 1,\n",
       "         'linkind': 1,\n",
       "         'edition': 1,\n",
       "         'dataentity': 1,\n",
       "         'community': 1,\n",
       "         'speaking': 1,\n",
       "         'german': 1,\n",
       "         'calll': 1,\n",
       "         'tuya': 1,\n",
       "         'derivative': 1,\n",
       "         'jory': 1,\n",
       "         'seek': 1,\n",
       "         'syntax': 1,\n",
       "         'coordinator': 1,\n",
       "         'energy': 1,\n",
       "         'translate': 1,\n",
       "         'heiman': 1,\n",
       "         'arm': 1,\n",
       "         'blitzhome': 1,\n",
       "         'spotify': 1,\n",
       "         'playermedia': 1,\n",
       "         'groups': 1,\n",
       "         'powerpoint': 1,\n",
       "         'reason': 1,\n",
       "         'stuck': 1,\n",
       "         'aircon': 1,\n",
       "         'sugestions': 1,\n",
       "         'written': 1,\n",
       "         'modification': 1,\n",
       "         'program': 1,\n",
       "         'yale': 1,\n",
       "         'speakers': 1,\n",
       "         'myhome': 1,\n",
       "         'cen': 1,\n",
       "         'profile': 1,\n",
       "         'ago': 1,\n",
       "         'goal': 1,\n",
       "         'die': 1,\n",
       "         'changed': 1,\n",
       "         'lots': 1,\n",
       "         'letv': 1,\n",
       "         'diyruz': 1,\n",
       "         'circadian': 1,\n",
       "         'heatit': 1,\n",
       "         'found': 1,\n",
       "         'blueiris': 1,\n",
       "         'rgb': 1,\n",
       "         'fjernkontroll': 1,\n",
       "         'recommend': 1,\n",
       "         'speedtest': 1,\n",
       "         'hassnic': 1,\n",
       "         'shellyforhass': 1,\n",
       "         'worked': 1,\n",
       "         'toilet': 1,\n",
       "         '환풍기': 1,\n",
       "         'slider': 1,\n",
       "         'setpoint': 1,\n",
       "         'silvercrest': 1,\n",
       "         'illumino': 1,\n",
       "         'aquara': 1,\n",
       "         'easy': 1,\n",
       "         'combine': 1,\n",
       "         'exists': 1,\n",
       "         'ids': 1,\n",
       "         'snoozed': 1,\n",
       "         'havent': 1,\n",
       "         'loop': 1,\n",
       "         'moestuya': 1,\n",
       "         'bonding': 1,\n",
       "         'console': 1,\n",
       "         'february': 1,\n",
       "         'zwaveme': 1,\n",
       "         'varied': 1,\n",
       "         'yifan': 1,\n",
       "         'step': 1,\n",
       "         'hank': 1,\n",
       "         'movement': 1,\n",
       "         'dmss': 1,\n",
       "         \"state'sunsun\": 1,\n",
       "         'horizon': 1,\n",
       "         'float': 1,\n",
       "         'zhq': 1,\n",
       "         'andré': 1,\n",
       "         'browser': 1,\n",
       "         'mod': 1,\n",
       "         'index': 1,\n",
       "         'weatherflow': 1,\n",
       "         'ptm': 1,\n",
       "         'wyze': 1,\n",
       "         'robot': 1,\n",
       "         'indoor': 1,\n",
       "         'hasp': 1,\n",
       "         'selected': 1,\n",
       "         'attempt': 1,\n",
       "         'ysrminiz': 1,\n",
       "         'tem': 1,\n",
       "         'free': 1,\n",
       "         'reference': 1,\n",
       "         'dictionary': 1,\n",
       "         'recognize': 1,\n",
       "         'dryer': 1,\n",
       "         'bluetooth': 1,\n",
       "         'location': 1,\n",
       "         'bright': 1,\n",
       "         'enocean': 1,\n",
       "         'love': 1,\n",
       "         'inventory': 1,\n",
       "         'states': 1,\n",
       "         'multipress': 1,\n",
       "         'solaredge': 1,\n",
       "         'fine': 1,\n",
       "         'title': 1,\n",
       "         'apple': 1,\n",
       "         'executed': 1,\n",
       "         'crockpot': 1,\n",
       "         'momentary': 1,\n",
       "         'milliseconds': 1,\n",
       "         'drink': 1,\n",
       "         'extended': 1,\n",
       "         'fired': 1,\n",
       "         'minimote': 1,\n",
       "         'echo': 1,\n",
       "         'tested': 1,\n",
       "         'fred': 1,\n",
       "         'brought': 1,\n",
       "         'makes': 1,\n",
       "         'enbrighten': 1,\n",
       "         'unsure': 1,\n",
       "         'cheap': 1,\n",
       "         'series': 1,\n",
       "         'black': 1,\n",
       "         'fire': 1,\n",
       "         'video': 1,\n",
       "         'experience': 1,\n",
       "         'wit': 1,\n",
       "         'months': 1,\n",
       "         'webhooks': 1,\n",
       "         'back': 1,\n",
       "         'outdoor': 1,\n",
       "         'ohmigo': 1,\n",
       "         'sunrise': 1,\n",
       "         'source': 1,\n",
       "         'muller': 1,\n",
       "         'firmware': 1,\n",
       "         'share': 1,\n",
       "         'correct': 1,\n",
       "         'fade': 1,\n",
       "         'consumption': 1,\n",
       "         'month': 1,\n",
       "         'magnet': 1,\n",
       "         'rolling': 1,\n",
       "         'bthome': 1,\n",
       "         'map': 1,\n",
       "         'snapshoot': 1,\n",
       "         'ten': 1,\n",
       "         'mins': 1,\n",
       "         'random': 1,\n",
       "         'timed': 1,\n",
       "         'learn': 1,\n",
       "         'payload': 1,\n",
       "         'minute': 1,\n",
       "         'fans': 1,\n",
       "         'insteon': 1,\n",
       "         'baby': 1,\n",
       "         'buddy': 1,\n",
       "         'low': 1,\n",
       "         'wanted': 1,\n",
       "         'eisy': 1,\n",
       "         'polyglot': 1,\n",
       "         'behaviour': 1,\n",
       "         'wheel': 1,\n",
       "         'heater': 1,\n",
       "         'buschjaeger': 1,\n",
       "         'statement': 1,\n",
       "         'puerta': 1,\n",
       "         'ventana': 1,\n",
       "         'segundos': 1,\n",
       "         'sliding': 1,\n",
       "         'houseshed': 1,\n",
       "         'master': 1,\n",
       "         'doors': 1,\n",
       "         'unknown': 1,\n",
       "         'require': 1,\n",
       "         'debug': 1,\n",
       "         'homeassistantcomponentszhacoredevice': 1,\n",
       "         'scholmore': 1,\n",
       "         'robb': 1,\n",
       "         'smarrt': 1,\n",
       "         'rob': 1,\n",
       "         'missing': 1,\n",
       "         'zen': 1,\n",
       "         'plug': 1,\n",
       "         'dose': 1,\n",
       "         'doser': 1,\n",
       "         'label': 1,\n",
       "         'raiselower': 1,\n",
       "         'dots': 1,\n",
       "         'paddles': 1,\n",
       "         'customizable': 1,\n",
       "         'project': 1,\n",
       "         'announcement': 1,\n",
       "         'receive': 1,\n",
       "         'exposure': 1,\n",
       "         'address': 1,\n",
       "         'bambulab': 1,\n",
       "         'bot': 1,\n",
       "         'local': 1,\n",
       "         'daynight': 1,\n",
       "         'middle': 1,\n",
       "         'reboot': 1,\n",
       "         'internet': 1,\n",
       "         'pollen': 1,\n",
       "         'iqair': 1,\n",
       "         'timeout': 1,\n",
       "         'labs': 1,\n",
       "         'aeon': 1,\n",
       "         'skip': 1,\n",
       "         'criteria': 1,\n",
       "         'encrypt': 1,\n",
       "         'expiry': 1,\n",
       "         'wrong': 1,\n",
       "         'pumps': 1,\n",
       "         'ezo': 1,\n",
       "         'leaves': 1,\n",
       "         'wallbox': 1,\n",
       "         'der': 1,\n",
       "         'soc': 1,\n",
       "         'opendtu': 1,\n",
       "         'finished': 1,\n",
       "         'polestar': 1,\n",
       "         'connect': 1,\n",
       "         'cabinet': 1,\n",
       "         'vpd': 1,\n",
       "         'maintaining': 1,\n",
       "         'unifi': 1,\n",
       "         'homeassistantturn': 1,\n",
       "         'celsius': 1,\n",
       "         'var': 1,\n",
       "         'localdeck': 1,\n",
       "         'type': 1,\n",
       "         'inside': 1,\n",
       "         'mine': 1,\n",
       "         'mac': 1,\n",
       "         'posted': 1,\n",
       "         'waste': 1,\n",
       "         'drying': 1,\n",
       "         'trash': 1,\n",
       "         'trvclimate': 1,\n",
       "         'connected': 1,\n",
       "         'mutually': 1,\n",
       "         'exclusive': 1,\n",
       "         'due': 1,\n",
       "         'eltako': 1,\n",
       "         'scenemy': 1,\n",
       "         'icons': 1,\n",
       "         'tint': 1,\n",
       "         'onoffleftright': 1,\n",
       "         'curtain': 1,\n",
       "         'receiver': 1,\n",
       "         'fits': 1,\n",
       "         'module': 1,\n",
       "         'confirmation': 1,\n",
       "         'team': 1,\n",
       "         'improve': 1,\n",
       "         'github': 1,\n",
       "         'options': 1,\n",
       "         'interval': 1,\n",
       "         'comparison': 1,\n",
       "         'phase': 1,\n",
       "         'aquarium': 1,\n",
       "         'caseta': 1,\n",
       "         'graph': 1,\n",
       "         'samsung': 1,\n",
       "         'tuyaloratap': 1,\n",
       "         'fuga': 1,\n",
       "         'onoffdimming': 1,\n",
       "         'stop': 1,\n",
       "         'friendly': 1,\n",
       "         'ultimate': 1,\n",
       "         'move': 1,\n",
       "         'column': 1,\n",
       "         'sheets': 1,\n",
       "         'pressed': 1,\n",
       "         'prayer': 1,\n",
       "         'islamic': 1,\n",
       "         'information': 1,\n",
       "         'joke': 1,\n",
       "         'jokes': 1,\n",
       "         'dad': 1,\n",
       "         'maintenance': 1,\n",
       "         'roborock': 1,\n",
       "         'wait': 1,\n",
       "         'emulated': 1,\n",
       "         'roku': 1,\n",
       "         'load': 1,\n",
       "         'elapsed': 1,\n",
       "         'appliance': 1,\n",
       "         'rgbw': 1,\n",
       "         'blockquote': 1,\n",
       "         'agenda': 1,\n",
       "         'plex': 1,\n",
       "         'kenny': 1,\n",
       "         'thermostats': 1,\n",
       "         'loxone': 1,\n",
       "         'duo': 1,\n",
       "         'search': 1,\n",
       "         'assign': 1,\n",
       "         'ordereddictscene': 1,\n",
       "         'pin': 1,\n",
       "         'pws': 1,\n",
       "         'upload': 1,\n",
       "         'nedis': 1,\n",
       "         'area': 1,\n",
       "         'eglo': 1,\n",
       "         'original': 1,\n",
       "         'keymaster': 1,\n",
       "         'caldav': 1,\n",
       "         'portable': 1,\n",
       "         'fob': 1,\n",
       "         'shield': 1,\n",
       "         'entering': 1,\n",
       "         'edit': 1,\n",
       "         'pill': 1,\n",
       "         'raw': 1,\n",
       "         'electric': 1,\n",
       "         'channels': 1,\n",
       "         'lot': 1,\n",
       "         'forecast': 1,\n",
       "         'eria': 1,\n",
       "         'triggerto': 1,\n",
       "         'leaving': 1,\n",
       "         'jesper': 1,\n",
       "         'gps': 1,\n",
       "         'ssid': 1,\n",
       "         'satellite': 1,\n",
       "         'async': 1,\n",
       "         'patterns': 1,\n",
       "         'bosch': 1,\n",
       "         'replay': 1,\n",
       "         'dutch': 1,\n",
       "         'afvalbeheer': 1,\n",
       "         'turns': 1,\n",
       "         'detection': 1,\n",
       "         'rotate': 1,\n",
       "         'sensorcert': 1,\n",
       "         'true': 1,\n",
       "         'variable': 1,\n",
       "         'functionality': 1,\n",
       "         'period': 1,\n",
       "         'grace': 1,\n",
       "         'contributing': 1,\n",
       "         'shopping': 1,\n",
       "         'easee': 1,\n",
       "         'hub': 1,\n",
       "         'special': 1,\n",
       "         'repeating': 1,\n",
       "         'alerts': 1,\n",
       "         'completed': 1,\n",
       "         'bermuda': 1,\n",
       "         'hour': 1,\n",
       "         'paused': 1,\n",
       "         'remotes': 1,\n",
       "         'rtl': 1,\n",
       "         'revise': 1,\n",
       "         'physical': 1,\n",
       "         'covered': 1,\n",
       "         'absolute': 1,\n",
       "         'product': 1,\n",
       "         'job': 1,\n",
       "         'hey': 1,\n",
       "         'faradite': 1,\n",
       "         'keypads': 1,\n",
       "         'grid': 1,\n",
       "         'levels': 1,\n",
       "         'auto': 1,\n",
       "         'installed': 1,\n",
       "         'cards': 1,\n",
       "         'shortdoublelong': 1,\n",
       "         'fun': 1,\n",
       "         'package': 1,\n",
       "         'count': 1,\n",
       "         'onvis': 1,\n",
       "         'kmh': 1,\n",
       "         'train': 1,\n",
       "         'sterkte': 1,\n",
       "         'protection': 1,\n",
       "         'indicator': 1,\n",
       "         'yolink': 1,\n",
       "         'virtualarm': 1,\n",
       "         'reliable': 1,\n",
       "         'sender': 1,\n",
       "         'bed': 1,\n",
       "         'instance': 1,\n",
       "         'numberbrightness': 1,\n",
       "         'detached': 1,\n",
       "         'picos': 1,\n",
       "         'ecobee': 1,\n",
       "         'vibration': 1,\n",
       "         'dehumidifier': 1,\n",
       "         'adurosmart': 1,\n",
       "         'travel': 1,\n",
       "         'chip': 1,\n",
       "         'linked': 1,\n",
       "         'pattern': 1,\n",
       "         'center': 1,\n",
       "         'question': 1,\n",
       "         'hook': 1,\n",
       "         'wunderground': 1,\n",
       "         'timerfinished': 1,\n",
       "         'runtime': 1,\n",
       "         'cooling': 1,\n",
       "         'badring': 1,\n",
       "         'leakage': 1,\n",
       "         'min': 1,\n",
       "         'important': 1,\n",
       "         'gist': 1,\n",
       "         'print': 1,\n",
       "         'watchdog': 1,\n",
       "         'main': 1,\n",
       "         'tesla': 1,\n",
       "         'conditioner': 1,\n",
       "         'blinking': 1,\n",
       "         'comfort': 1,\n",
       "         'save': 1,\n",
       "         'ring': 1,\n",
       "         'valetudo': 1,\n",
       "         'shading': 1,\n",
       "         'nspanel': 1,\n",
       "         'tft': 1,\n",
       "         'panel': 1,\n",
       "         'contact': 1,\n",
       "         'driver': 1,\n",
       "         'order': 1,\n",
       "         'eats': 1,\n",
       "         'roundup': 1,\n",
       "         'rewrite': 1,\n",
       "         'outlet': 1,\n",
       "         'prices': 1,\n",
       "         'appliances': 1,\n",
       "         'kwh': 1,\n",
       "         'opensensemap': 1,\n",
       "         'booleans': 1,\n",
       "         'cleaning': 1,\n",
       "         'dreame': 1,\n",
       "         'inteligent': 1,\n",
       "         'rate': 1,\n",
       "         'slide': 1,\n",
       "         'resetting': 1,\n",
       "         'cooldown': 1,\n",
       "         'bound': 1,\n",
       "         'moved': 1,\n",
       "         'goodwe': 1,\n",
       "         'homewizard': 1,\n",
       "         'export': 1})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yake_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, top=2)\n",
    "yake_kw_extractor.stopword_set.add('blueprint')\n",
    "keywords = Counter()\n",
    "for topic_id in tqdm.tqdm(list(filtered_groups.keys()), desc=\"Extracting keywords\"):\n",
    "    posts = db.get_posts_by_topic_id(topic_id)\n",
    "    cleaned_texts = [yake_preprocessing(post.cooked) for post in posts]\n",
    "    cleaned_texts.insert(0, yake_preprocessing(topics.get(topic_id).title))\n",
    "    full_text = \" \".join(cleaned_texts)\n",
    "    tags = topics.get(topic_id).tags\n",
    "    if isinstance(tags, str):\n",
    "        try:\n",
    "            tags = ast.literal_eval(tags)\n",
    "        except (ValueError, SyntaxError):\n",
    "            tags = [tags]\n",
    "    #print(f\"Topic ID: {topic_id}, Tags: {tags}\")\n",
    "    for tag in tags:\n",
    "        yake_kw_extractor.stopword_set.add(tag.lower())\n",
    "    yake_keywords = yake_kw_extractor.extract_keywords(full_text)\n",
    "    yake_keywords = [kw for kw, score in yake_keywords]\n",
    "    keywords.update(yake_keywords)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29af0c7",
   "metadata": {},
   "source": [
    "### KeyBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01218d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1841424ffe4ca1b22f2454b24b8a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Adrian\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8536490bdeb4a879407658a397bb3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9481d3d9fe54d2192c9f20a40d54443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a77c4eb36f34429b3ec7daa42054ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2384b6ce127348fa8026a99fefefa2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec44dccdec445c6bc9b3dfe5c3692cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771cd8b2945a480db7ff70e3696a1d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d7e77e93e24a569e26c8e154996276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c692818609442c85871d3123a01d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c2f01d414b42a38451f052cb837bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a307d5127ba94dc48a6f544227a1ef92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('phoscon', 0.3929),\n",
       " ('deconz_event', 0.3369),\n",
       " ('ikea', 0.3358),\n",
       " ('shortcut', 0.286),\n",
       " ('button', 0.2822),\n",
       " ('buttons', 0.2743),\n",
       " ('deconz', 0.2598),\n",
       " ('blueprint', 0.2569),\n",
       " ('tradfri', 0.2526),\n",
       " ('blueprints', 0.2352)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "from keybert import KeyBERT\n",
    "bert_topic_id = list(filtered_groups.keys())[115]\n",
    "bert_posts = db.get_posts_by_topic_id(bert_topic_id)\n",
    "cleaned_texts_bert = [remove_html(post.cooked) for post in bert_posts]\n",
    "cleaned_texts_bert.insert(0, str(topics.get(bert_topic_id).title))\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(\" \".join(cleaned_texts_bert), keyphrase_ngram_range=(1, 1), stop_words='english', top_n=10)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c35ad1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>post_id</th>\n",
       "      <th>cooked</th>\n",
       "      <th>bp_id</th>\n",
       "      <th>blueprint_code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255041</td>\n",
       "      <td>Nag prompt Blueprint (Android Notification)</td>\n",
       "      <td>[]</td>\n",
       "      <td>1220860</td>\n",
       "      <td>&lt;p&gt;This blueprints creates configurable nag no...</td>\n",
       "      <td>1</td>\n",
       "      <td>blueprint:\\n  name: Nag prompt blueprint\\n  de...</td>\n",
       "      <td>Nag a mobile device to do something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254999</td>\n",
       "      <td>Inovelli LZW36 Fan/Dimmer Scenes</td>\n",
       "      <td>[\"blueprint\"]</td>\n",
       "      <td>1220678</td>\n",
       "      <td>&lt;p&gt;This blueprint allows you to easily create ...</td>\n",
       "      <td>2</td>\n",
       "      <td>blueprint:\\n  name: Inovelli \\n  description: ...</td>\n",
       "      <td>Use this blueprint to create automations based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255699</td>\n",
       "      <td>deCONZ - IKEA five button remote</td>\n",
       "      <td>[\"switch\", \"blueprint\", \"deconz\"]</td>\n",
       "      <td>1223455</td>\n",
       "      <td>&lt;p&gt;This is a mix of &lt;a href=\"https://community...</td>\n",
       "      <td>3</td>\n",
       "      <td>blueprint:\\n  name: deCONZ - IKEA five button ...</td>\n",
       "      <td>Control anything using IKEA five button remote\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255742</td>\n",
       "      <td>Set heating temperature to a configurable valu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1223628</td>\n",
       "      <td>&lt;p&gt;This is a blueprint, that allows to set the...</td>\n",
       "      <td>4</td>\n",
       "      <td>blueprint:\\n  name: Heat for certain time\\n  d...</td>\n",
       "      <td>Turn on heating for a given amount of time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256045</td>\n",
       "      <td>Light Allowance</td>\n",
       "      <td>[]</td>\n",
       "      <td>1224871</td>\n",
       "      <td>&lt;p&gt;This blueprint will turn a light off after ...</td>\n",
       "      <td>5</td>\n",
       "      <td>blueprint:\\n  name: Light Allowance\\n  descrip...</td>\n",
       "      <td>Turns a light off after an allotted time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic_id                                              title  \\\n",
       "0   255041        Nag prompt Blueprint (Android Notification)   \n",
       "1   254999                   Inovelli LZW36 Fan/Dimmer Scenes   \n",
       "2   255699                   deCONZ - IKEA five button remote   \n",
       "3   255742  Set heating temperature to a configurable valu...   \n",
       "4   256045                                    Light Allowance   \n",
       "\n",
       "                                tags  post_id  \\\n",
       "0                                 []  1220860   \n",
       "1                      [\"blueprint\"]  1220678   \n",
       "2  [\"switch\", \"blueprint\", \"deconz\"]  1223455   \n",
       "3                                 []  1223628   \n",
       "4                                 []  1224871   \n",
       "\n",
       "                                              cooked  bp_id  \\\n",
       "0  <p>This blueprints creates configurable nag no...      1   \n",
       "1  <p>This blueprint allows you to easily create ...      2   \n",
       "2  <p>This is a mix of <a href=\"https://community...      3   \n",
       "3  <p>This is a blueprint, that allows to set the...      4   \n",
       "4  <p>This blueprint will turn a light off after ...      5   \n",
       "\n",
       "                                      blueprint_code  \\\n",
       "0  blueprint:\\n  name: Nag prompt blueprint\\n  de...   \n",
       "1  blueprint:\\n  name: Inovelli \\n  description: ...   \n",
       "2  blueprint:\\n  name: deCONZ - IKEA five button ...   \n",
       "3  blueprint:\\n  name: Heat for certain time\\n  d...   \n",
       "4  blueprint:\\n  name: Light Allowance\\n  descrip...   \n",
       "\n",
       "                                         description  \n",
       "0                Nag a mobile device to do something  \n",
       "1  Use this blueprint to create automations based...  \n",
       "2   Control anything using IKEA five button remote\\n  \n",
       "3        Turn on heating for a given amount of time.  \n",
       "4           Turns a light off after an allotted time  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame([{\n",
    "    \"topic_id\": topic.topic_id,\n",
    "    \"title\": topic.title,\n",
    "    \"tags\": topic.tags,\n",
    "} for topic in topics.values()])\n",
    "posts_df = pd.DataFrame([{\n",
    "    \"post_id\": post.post_id,\n",
    "    \"topic_id\": post.topic_id,\n",
    "    \"cooked\": post.cooked,\n",
    "} for post in posts.values()])\n",
    "bp_df = pd.DataFrame([{\n",
    "    \"bp_id\": bp.id,\n",
    "    \"blueprint_code\": bp.blueprint_code,\n",
    "    \"post_id\": bp.post_id,\n",
    "    \"description\": bp.description,\n",
    "} for bp in blueprints.values()])\n",
    "topics_posts = topics_df.merge(posts_df, on=\"topic_id\")\n",
    "topics_bps = topics_posts.merge(bp_df, on=\"post_id\")\n",
    "topics_bps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8cfb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2196, 8), (36624, 5))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_bps = topics_bps[topics_bps[\"topic_id\"].isin(filtered_groups.keys())]\n",
    "topics_posts = topics_posts[topics_posts[\"topic_id\"].isin(filtered_groups.keys())]\n",
    "topics_bps.shape, topics_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f13f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['notification'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['media_player'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'mqtt', 'zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['cover'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['climate'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'switch', 'zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lutron', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'timestamp'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['xiaomi', 'zigbee', 'zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['cover', 'deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['device_automations', 'templates', 'zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['addon', 'notification'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'templates'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['media_player'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['templates', 'zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lovelace'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'tasmota'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['templates'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['climate'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'switch', 'xiaomi'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['templates'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lutron', 'media_player'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['button', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'switch', 'zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'xiaomi', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'mqtt', 'tasmota'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'templates'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'switch', 'templates', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ios', 'notification', 'official_mobile_app'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['alexa', 'official_mobile_app'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'lights', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'mqtt', 'switch', 'zigbee', 'zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'xiaomi', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['button', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'notification', 'script'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['googleassistant'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['templates'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'templates', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['sonoff', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['notification'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['notification'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['device_automations'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['alexa', 'ios'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['climate', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['addon', 'templates'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'xiaomi'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'switch', 'zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['alexa', 'notification'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['addon', 'assistant', 'home', 'os', 'templates'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['backup'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['templates', 'time'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'templates', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['button', 'zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz', 'switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'switch', 'zigbee', 'zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'switch', 'zigbee', 'zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aqara', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['cover', 'deconz', 'switch', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['button', 'deconz', 'lights', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['mqtt', 'switch', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['media_player', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['templates', 'zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights', 'lutron', 'switch', 'zha'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zha', 'zigbee'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['notification'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['googleassistant'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['deconz'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zigbee2mqtt'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lights'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch', 'zwave'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['switch'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['zwave'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m     texts.extend(bp_subset[\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m].tolist())\n\u001b[32m     10\u001b[39m     text = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(texts)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     keywords = \u001b[43mkw_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_keywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstop_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_subset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m+\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mblueprint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mautomation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     kw_dict[topic_id] = keywords\n\u001b[32m     14\u001b[39m kw_df = pd.DataFrame(kw_dict).T\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\keybert\\_model.py:199\u001b[39m, in \u001b[36mKeyBERT.extract_keywords\u001b[39m\u001b[34m(self, docs, candidates, keyphrase_ngram_range, stop_words, top_n, min_df, use_maxsum, use_mmr, diversity, nr_candidates, vectorizer, highlight, seed_keywords, doc_embeddings, word_embeddings, threshold)\u001b[39m\n\u001b[32m    197\u001b[39m     doc_embeddings = \u001b[38;5;28mself\u001b[39m.model.embed(docs)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m word_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     word_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# Guided KeyBERT either local (keywords shared among documents) or global (keywords per document)\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seed_keywords \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\keybert\\backend\\_sentencetransformers.py:65\u001b[39m, in \u001b[36mSentenceTransformerBackend.embed\u001b[39m\u001b[34m(self, documents, verbose)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Embed a list of n documents/words into an n-dimensional\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03mmatrix of embeddings.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m \u001b[33;03m    that each have an embeddings size of `m`\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mself\u001b[39m.encode_kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mshow_progress_bar\u001b[39m\u001b[33m\"\u001b[39m: verbose})\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:558\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    556\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    557\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    567\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:488\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    479\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    486\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    487\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    498\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:387\u001b[39m, in \u001b[36mBertSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    384\u001b[39m     value_layer = curr_past_key_value.layers[\u001b[38;5;28mself\u001b[39m.layer_idx].values\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    386\u001b[39m     key_layer = (\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m         .view(bsz, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size)\n\u001b[32m    389\u001b[39m         .transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    390\u001b[39m     )\n\u001b[32m    391\u001b[39m     value_layer = (\n\u001b[32m    392\u001b[39m         \u001b[38;5;28mself\u001b[39m.value(current_states)\n\u001b[32m    393\u001b[39m         .view(bsz, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size)\n\u001b[32m    394\u001b[39m         .transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    395\u001b[39m     )\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m         \u001b[38;5;66;03m# save all key/value_layer to cache to be re-used for fast auto-regressive generation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Adrian\\workspace-loc\\dat300\\BP-classification\\bpclass\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "kw_model = KeyBERT()\n",
    "kw_dict = {}\n",
    "for topic_id in topics_posts[\"topic_id\"].unique():\n",
    "    post_subset = topics_posts[topics_posts[\"topic_id\"] == topic_id]\n",
    "    bp_subset = topics_bps[topics_bps[\"topic_id\"] == topic_id]\n",
    "    texts = post_subset[\"cooked\"].tolist()\n",
    "    texts = [remove_html(post) for post in texts]\n",
    "    texts.insert(0, str(topics_df.loc[topics_df[\"topic_id\"] == topic_id, \"title\"].values[0]))\n",
    "    texts.extend(bp_subset[\"description\"].tolist())\n",
    "    text = \" \".join(texts)\n",
    "    \n",
    "    keywords = kw_model.extract_keywords(text,stop_words=post_subset[\"tags\"].tolist()+[\"blueprint\", \"automation\"], top_n=2)\n",
    "    kw_dict[topic_id] = keywords\n",
    "\n",
    "kw_df = pd.DataFrame(kw_dict).T\n",
    "kw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "kw_counts = Counter((kw_df[0]+kw_df[1]).explode())\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.bar(*zip(*kw_counts.most_common(20)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601098c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
